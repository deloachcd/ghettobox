# NOTE
# this docker-compose.yml file is written as a Jinja2 template
# by Ansible - all inventory vars & secrets, facts and register
# contents defined during provisioning can be referenced in this
# file, and have their literal values written

version: '3'
services:
  # filebrowser - web file manager
  filebrowser:
    image: filebrowser/filebrowser:latest
    # TODO: simplify this whole thing
    healthcheck:
      test: curl -f http://localhost:8080/health || exit 1
    user: '{{ gb_user_uid }}:{{ gb_user_gid }}'
    volumes:
      - '{{ filebrowser_root_path }}:/srv'
      - ./volumes/filebrowser/database.db:/database.db
      - ./volumes/filebrowser/filebrowser.json:/.filebrowser.json
    ports:
    - 8080:8080
    logging:
      driver: journald
    restart: unless-stopped

  # navidrome - self-hosted spotify
  navidrome:
    image: deluan/navidrome:latest
    user: '{{ gb_user_uid }}:{{ gb_user_gid }}'
    ports:
      - 4533:4533
    environment:
      ND_CONFIGFILE: /data/config.toml
    volumes:
      - ./volumes/navidrome:/data
      - '{{ navidrome_music_path }}:/music:ro'
    logging:
      driver: journald
    restart: unless-stopped

  # jellyfin - self-hosted netflix
  jellyfin:
    image: jellyfin/jellyfin:latest
    user: '{{ gb_user_uid }}:{{ gb_user_gid }}'
    ports:
      - 8096:8096
    volumes:
      - "{{ gb_root }}/volumes/jellyfin/config:/config"
      - "{{ gb_root }}/volumes/jellyfin/cache:/cache"
      - "{{ jellyfin_media_path }}:/media:ro"
    restart: unless-stopped

  # samba - network shares that every OS supports easily
  samba:
    image: crazymax/samba:latest
    ports:
      - 139:139
      - 445:445
    volumes:
      - "{{ gb_root }}/volumes/samba/data:/data"
      - '{{ samba_share_path }}:/samba/ghettobox'
    environment:
      TZ: "{{ local_timezone }}"
    restart: unless-stopped

  # caddy - reverse proxy for important services
  caddy:
    image: slothcroissant/caddy-cloudflaredns:latest
    volumes:
      - '{{ gb_root }}/volumes/caddy/data:/data'
      - '{{ gb_root }}/volumes/caddy/config:/config'
      - '{{ gb_root }}/volumes/caddy/Caddyfile:/etc/caddy/Caddyfile'
    network_mode: host
    environment:
      GB_DOMAIN: "{{ gb_domain }}"
      CLOUDFLARE_API_TOKEN: "{{ cloudflare_api_token }}"
      CLOUDFLARE_EMAIL: "{{ cloudflare_email }}"
      ACME_AGREE: "{{ true }}"
    restart: unless-stopped

  # baikal - calendar service
  baikal:
    image: ckulka/baikal:nginx
    ports:
      - 5232:80
    volumes:
      - "{{ gb_root }}/volumes/baikal/config:/var/www/baikal/config"
      - "{{ gb_root }}/volumes/baikal/Specific:/var/www/baikal/Specific"
    restart: unless-stopped

  # gluetun - VPN connection in a container
  gluetun:
    image: qmcgaw/gluetun:latest
    cap_add:
      - NET_ADMIN
    volumes:
      - '{{ gb_root }}/volumes/gluetun:/gluetun'
    environment:
      VPN_SERVICE_PROVIDER: "{{ openvpn_provider }}"
      OPENVPN_USER: "{{ openvpn_username }}"
      OPENVPN_PASSWORD: "{{ openvpn_password }}"
      SERVER_REGIONS: "{{ openvpn_server_regions }}"
      # port forwarding for private internet access -
      # config would be different for different VPN providers
      PRIVATE_INTERNET_ACCESS_VPN_PORT_FORWARDING: "on"
      PRIVATE_INTERNET_ACCESS_VPN_PORT_FORWARDING_STATUS_FILE: "/gluetun/forwarded_port"
    healthcheck:
      test: test -e /gluetun/forwarded_port || exit 1
      interval: 60s
      retries: 0
    ports:
      # ports for transmission
      - 9091:9091
      # ports for soulseek/slskd
      - 5030:5030
    restart: unless-stopped

  # transmission - classic bittorrent client, now with a webUI
  transmission:
    image: lscr.io/linuxserver/transmission:latest
    network_mode: "service:gluetun"
    healthcheck:
      test: ping -c1 1.1.1.1 || exit 1
      start_period: 60s
      interval: 10s
      timeout: 10s
      retries: 5
    labels:
      autoheal: "true"
    volumes:
      - '{{ gb_root }}/volumes/transmission/config:/config'
      - '{{ gb_root }}/volumes/transmission/watch:/watch'
      - '{{ gb_root }}/volumes/gluetun:/gluetun:ro' # used to read forwarded_port
      - '{{ transmission_share_path }}:/downloads'
    environment:
      PUID: '{{ gb_user_uid }}'
      PGID: '{{ gb_user_gid }}'
      USER: "{{ transmission_username }}"
      PASS: "{{ transmission_password }}"
      FILE__PEERPORT: "/gluetun/forwarded_port" # set port forward from file
    restart: unless-stopped
    
  # soulseek - limewire for a new generation
  slskd:
    image: slskd/slskd
    network_mode: "service:gluetun"
    healthcheck:
      test: ping -c1 1.1.1.1 || exit 1
      start_period: 60s
      interval: 10s
      timeout: 10s
      retries: 5
    labels:
      autoheal: "true"
    user: '{{ gb_user_uid }}:{{ gb_user_gid }}'
    environment:
      SLSKD_REMOTE_CONFIGURATION: "true"
      SLSKD_SHARED_DIR: "/share"
      SLSKD_SLSK_USERNAME: "{{ soulseek_username }}"
      SLSKD_SLSK_PASSWORD: "{{ soulseek_password }}"
      SLSKD_USERNAME: "{{ slskd_username }}"
      SLSKD_PASSWORD: "{{ slskd_password }}"
    volumes:
      - '{{ gb_root }}/volumes/slskd:/app'
      - '{{ soulseek_share_path }}:/share'
    restart: unless-stopped

  # restart containers labelled with "autoheal:true" on health check fail
  autoheal:
    image: willfarrell/autoheal:1.2.0
    volumes:
      - '/var/run/docker.sock:/var/run/docker.sock' # ARE YA FEELIN IT MR KRABS?
    restart: unless-stopped

  # restic - automatic backups for important data
  restic-backup:
    image: mazzolino/restic:latest
    environment:
      BACKUP_CRON: '{{ restic_backup_schedule }}'
      RESTIC_PASSWORD: ghettobox
      RESTIC_REPOSITORY: /mnt/restic
      RESTIC_BACKUP_SOURCES: /data
      RESTIC_BACKUP_ARGS: --tag docker-volumes --verbose
      RESTIC_FORGET_ARGS: --keep-last {{ restic_keep_last }}
      TZ: '{{ local_timezone }}'
    volumes:
      - '{{ restic_backup_src }}:/data:ro'
      - '{{ restic_backup_path }}:/mnt/restic'

  restic-prune:
    image: mazzolino/restic:latest
    environment:
      PRUNE_CRON: '{{ restic_prune_schedule }}'
      RESTIC_REPOSITORY: /mnt/restic
      RESTIC_PASSWORD: ghettobox
      TZ: '{{ local_timezone }}'
    volumes:
      - '{{ restic_backup_path }}:/mnt/restic'
